{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":5962731,"sourceType":"datasetVersion","datasetId":3419493}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport re\nfrom collections import defaultdict\n\nDATASET_PATH = '/kaggle/input/imagesoasis/Data'\nlabel_map = {\n    'Non Demented': 0,\n    'Very mild Dementia': 1,\n    'Mild Dementia': 2,\n    'Moderate Dementia': 3\n}\n\n# Group image paths per patient\npatient_dict = defaultdict(list)\n\nfor label_name in label_map:\n    folder = os.path.join(DATASET_PATH, label_name)\n    for fname in os.listdir(folder):\n        match = re.match(r\"(OAS1_\\d+)_MR1\", fname)\n        if match:\n            patient_id = match.group(1)\n            full_path = os.path.join(folder, fname)\n            patient_dict[(patient_id, label_map[label_name])].append(full_path)\n\n# Sort slice paths per patient (important for volume stacking)\nfor key in patient_dict:\n    patient_dict[key] = sorted(patient_dict[key])\n\nprint(f\"Total patients found: {len(patient_dict)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T20:02:30.44319Z","iopub.execute_input":"2025-05-11T20:02:30.443784Z","iopub.status.idle":"2025-05-11T20:02:31.779393Z","shell.execute_reply.started":"2025-05-11T20:02:30.443748Z","shell.execute_reply":"2025-05-11T20:02:31.778657Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport cv2\nfrom tqdm import tqdm\n\nIMG_SIZE = 128\nDEPTH = 60  # Number of slices per volume\n\nX_volumes = []\ny_labels = []\n\nfor (pid, label), slices in tqdm(patient_dict.items()):\n    volume = []\n\n    for path in slices:\n        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n        volume.append(img)\n\n    volume = np.array(volume)\n\n    # Pad or crop to DEPTH\n    if volume.shape[0] < DEPTH:\n        pad_width = DEPTH - volume.shape[0]\n        pad = np.zeros((pad_width, IMG_SIZE, IMG_SIZE))\n        volume = np.concatenate([volume, pad], axis=0)\n    else:\n        mid = volume.shape[0] // 2\n        start = max(0, mid - DEPTH // 2)\n        volume = volume[start:start+DEPTH]\n\n    # Normalize and store\n    volume = volume.astype('float32') / 255.0\n    X_volumes.append(volume)\n    y_labels.append(label)\n\nX_volumes = np.stack(X_volumes)\ny_labels = np.array(y_labels)\nprint(f\"X shape: {X_volumes.shape}, y shape: {y_labels.shape}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T20:03:09.184481Z","iopub.execute_input":"2025-05-11T20:03:09.185088Z","iopub.status.idle":"2025-05-11T20:17:14.389842Z","shell.execute_reply.started":"2025-05-11T20:03:09.185063Z","shell.execute_reply":"2025-05-11T20:17:14.389181Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nimport torch\nfrom torch.utils.data import TensorDataset, DataLoader\n\n# Train-test split\nX_train, X_test, y_train, y_test = train_test_split(\n    X_volumes, y_labels, test_size=0.2, stratify=y_labels, random_state=42\n)\n\n# Convert to PyTorch tensors and reshape for 3D CNN: (N, 1, D, H, W)\nX_train_tensor = torch.tensor(X_train).unsqueeze(1).float()\nX_test_tensor = torch.tensor(X_test).unsqueeze(1).float()\ny_train_tensor = torch.tensor(y_train).long()\ny_test_tensor = torch.tensor(y_test).long()\n\n# DataLoader\ntrain_ds = TensorDataset(X_train_tensor, y_train_tensor)\ntest_ds = TensorDataset(X_test_tensor, y_test_tensor)\n\ntrain_loader = DataLoader(train_ds, batch_size=4, shuffle=True)\ntest_loader = DataLoader(test_ds, batch_size=4, shuffle=False)\n\nprint(f\"Train loader size: {len(train_loader)}, Test loader size: {len(test_loader)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T20:22:23.967526Z","iopub.execute_input":"2025-05-11T20:22:23.967818Z","iopub.status.idle":"2025-05-11T20:22:29.268538Z","shell.execute_reply.started":"2025-05-11T20:22:23.967796Z","shell.execute_reply":"2025-05-11T20:22:29.267703Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch.nn as nn\nfrom torchvision.models.video import r3d_18\n\nclass DenseNet3D(nn.Module):\n    def __init__(self, num_classes=4):\n        super(DenseNet3D, self).__init__()\n        # Use 3D ResNet-18 (you can replace this with DenseNet3D later)\n        self.backbone = r3d_18(pretrained=False)\n        self.backbone.stem[0] = nn.Conv3d(1, 64, kernel_size=(3,7,7), stride=(1,2,2), padding=(1,3,3), bias=False)\n        self.backbone.fc = nn.Linear(self.backbone.fc.in_features, num_classes)\n\n    def forward(self, x):\n        return self.backbone(x)\n\n# Instantiate model\nmodel = DenseNet3D().to(\"cuda\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T20:23:49.260004Z","iopub.execute_input":"2025-05-11T20:23:49.26059Z","iopub.status.idle":"2025-05-11T20:23:49.964782Z","shell.execute_reply.started":"2025-05-11T20:23:49.260563Z","shell.execute_reply":"2025-05-11T20:23:49.963867Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch.optim as optim\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=1e-4)\n\n# Training loop\nepochs = 10\nfor epoch in range(epochs):\n    model.train()\n    train_loss, correct, total = 0, 0, 0\n\n    for X_batch, y_batch in train_loader:\n        X_batch, y_batch = X_batch.to(\"cuda\"), y_batch.to(\"cuda\")\n\n        outputs = model(X_batch)\n        loss = criterion(outputs, y_batch)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        train_loss += loss.item()\n        _, preds = torch.max(outputs, 1)\n        correct += (preds == y_batch).sum().item()\n        total += y_batch.size(0)\n\n    acc = 100 * correct / total\n    print(f\"Epoch {epoch+1}/{epochs} | Loss: {train_loss:.4f} | Train Acc: {acc:.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T20:24:36.828218Z","iopub.execute_input":"2025-05-11T20:24:36.828798Z","iopub.status.idle":"2025-05-11T20:33:45.03451Z","shell.execute_reply.started":"2025-05-11T20:24:36.828776Z","shell.execute_reply":"2025-05-11T20:33:45.033736Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\n\n# Set model to evaluation mode\nmodel.eval()\ny_true, y_pred = [], []\n\n# Run predictions on test set\nwith torch.no_grad():\n    for X_batch, y_batch in test_loader:\n        X_batch = X_batch.to(\"cuda\")\n        outputs = model(X_batch)\n        preds = torch.argmax(outputs, dim=1).cpu().numpy()\n\n        y_pred.extend(preds)\n        y_true.extend(y_batch.numpy())\n\n# Accuracy\ntest_acc = accuracy_score(y_true, y_pred)\nprint(f\"\\nTest Accuracy: {test_acc:.4f}\\n\")\n\n# Confusion matrix\ncm = confusion_matrix(y_true, y_pred)\nplt.figure(figsize=(6, 5))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n            xticklabels=[k for i, k in enumerate(label_map.keys()) if i in np.unique(y_true)],\n            yticklabels=[k for i, k in enumerate(label_map.keys()) if i in np.unique(y_true)])\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"True\")\nplt.title(\"Confusion Matrix\")\nplt.show()\n\n# Classification report (auto-select valid labels only)\nunique_labels = np.unique(y_true + y_pred)\ninv_label_map = {v: k for k, v in label_map.items()}\ntarget_names = [inv_label_map[i] for i in unique_labels]\n\nprint(\"Classification Report:\\n\")\nprint(classification_report(y_true, y_pred, target_names=target_names))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T20:37:19.976718Z","iopub.execute_input":"2025-05-11T20:37:19.97759Z","iopub.status.idle":"2025-05-11T20:37:24.335549Z","shell.execute_reply.started":"2025-05-11T20:37:19.977558Z","shell.execute_reply":"2025-05-11T20:37:24.33499Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import roc_curve, auc\nfrom sklearn.preprocessing import label_binarize\nfrom itertools import cycle\n\n# One-hot encode true labels\nn_classes = len(np.unique(y_true))\ny_true_bin = label_binarize(y_true, classes=sorted(list(np.unique(y_true))))\n\n# Get softmax scores\ny_scores = []\n\nmodel.eval()\nwith torch.no_grad():\n    for X_batch, _ in test_loader:\n        X_batch = X_batch.to(\"cuda\")\n        probs = torch.softmax(model(X_batch), dim=1)\n        y_scores.extend(probs.cpu().numpy())\n\ny_scores = np.array(y_scores)\n\n# Compute ROC curve and AUC\nfpr, tpr, roc_auc = {}, {}, {}\nfor i in range(n_classes):\n    fpr[i], tpr[i], _ = roc_curve(y_true_bin[:, i], y_scores[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n\n# Plot all ROC curves\nplt.figure(figsize=(8, 6))\ncolors = cycle(['blue', 'red', 'green', 'orange'])\ninv_label_map = {v: k for k, v in label_map.items()}\nlabels_present = sorted(np.unique(y_true))\n\nfor i, color in zip(range(n_classes), colors):\n    label_name = inv_label_map[labels_present[i]]\n    plt.plot(fpr[i], tpr[i], color=color, lw=2,\n             label=f'{label_name} (AUC = {roc_auc[i]:.2f})')\n\nplt.plot([0, 1], [0, 1], 'k--', lw=2)\nplt.xlim([-0.01, 1.01])\nplt.ylim([-0.01, 1.01])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Multi-Class ROC Curve')\nplt.legend(loc='lower right')\nplt.grid()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T20:39:28.609268Z","iopub.execute_input":"2025-05-11T20:39:28.609871Z","iopub.status.idle":"2025-05-11T20:39:32.987463Z","shell.execute_reply.started":"2025-05-11T20:39:28.609829Z","shell.execute_reply":"2025-05-11T20:39:32.986618Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"torch.save(model.state_dict(), \"multimask_densenet3d_alzheimer.pth\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T20:49:03.272717Z","iopub.execute_input":"2025-05-11T20:49:03.273392Z","iopub.status.idle":"2025-05-11T20:49:03.454125Z","shell.execute_reply.started":"2025-05-11T20:49:03.273368Z","shell.execute_reply":"2025-05-11T20:49:03.453344Z"}},"outputs":[],"execution_count":null}]}